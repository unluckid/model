{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jX7ukQPOAxrM"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/rickiepark/handson-ml3/blob/main/12_custom_models_and_training_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFcMpxP2AxrN",
        "tags": []
      },
      "source": [
        "# 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xNKQVwanAxrN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "675bac04-8273-4c57-9b69-f889efa7a20e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=181xBl-rU9gBAL8-iEZbPNxKzPZY-QCGu\n",
            "From (redirected): https://drive.google.com/uc?id=181xBl-rU9gBAL8-iEZbPNxKzPZY-QCGu&confirm=t&uuid=b86dba6b-dd00-4ae0-b8c1-568901641bee\n",
            "To: /content/dataset.zip\n",
            "100%|██████████| 1.65G/1.65G [00:25<00:00, 64.3MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/dataset.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import gdown\n",
        "import numpy as np\n",
        "\n",
        "file_id = '181xBl-rU9gBAL8-iEZbPNxKzPZY-QCGu'\n",
        "download_url = f'https://drive.google.com/uc?id={file_id}'\n",
        "\n",
        "\n",
        "destination_path = '/content/dataset.zip'  # 파일 경로 설정\n",
        "\n",
        "# 다운로드 시작\n",
        "gdown.download(download_url, destination_path, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0Ddo9OPsAxrO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64eb7a45-d2d7-43af-aec3-26a747bd9b19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "압축이 /content/에 해제되었습니다.\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "\n",
        "zip_file_path = '/content/dataset.zip'\n",
        "extract_path = '/content/'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"압축이 {extract_path}에 해제되었습니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN8_1_vCAxrP",
        "outputId": "4b034ec8-8f2b-47f0-b852-b6e688867510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "폴더 초기화\n",
            "setting folder\n",
            "error_00: _ari: 동영상 없음 \n",
            "프레임 분할 완료!\n",
            "error_00: _smallthe: 동영상 없음 \n",
            "프레임 분할 완료!\n",
            "프레임 분할 완료!\n",
            "프레임 분할 완료!\n",
            "프레임 분할 완료!\n",
            "프레임 분할 완료!\n",
            "프레임 분할 완료!\n",
            "프레임 분할 완료!\n",
            "프레임 분할 완료!\n",
            "프레임 분할 완료!\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "setting folder\n",
            "error_00: _ari: 동영상 없음 \n",
            "프레임 분할 완료!\n",
            "error_00: _smallthe: 동영상 없음 \n",
            "프레임 분할 완료!\n",
            "프레임 분할 완료!\n",
            "프레임 분할 완료!\n",
            "프레임 분할 완료!\n",
            "프레임 분할 완료!\n",
            "프레임 분할 완료!\n",
            "프레임 분할 완료!\n",
            "프레임 분할 완료!\n",
            "프레임 분할 완료!\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n",
            "이미지 전처리  패스 설정 완료\n"
          ]
        }
      ],
      "source": [
        "!python Image_propressing.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "V1OI3MGjAxrQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import VotingClassifier,BaggingClassifier\n",
        "\n",
        "class Model:\n",
        "    def __init__(self):\n",
        "        self.models = []\n",
        "        self.model  = None\n",
        "        self.model1 = None\n",
        "        self.model2 = None\n",
        "        self.train_dir = \"train/model1\"\n",
        "        self.val_dir = \"val/model1\"\n",
        "        self.train_dir1 = \"train/model2\"\n",
        "        self.val_dir1 = \"val/model2\"\n",
        "        self.bagging_model1 = None\n",
        "        self.bagging_model2 = None\n",
        "        self.train_dataset\n",
        "        self.val_dataset\n",
        "        self.color =\"rgb\"\n",
        "        self.gray = \"gray\"\n",
        "    def setmodel1(self):\n",
        "        self.model1 = models.Sequential()\n",
        "        self.model1.add( layers.Conv2D(filters = 32,kernel_size = (3,3), activation= 'relu', input_shape=(240,240,3), strides = (1,1), padding = 'same')) #128\n",
        "        self.model1.add( layers.BatchNormalization())\n",
        "        self.model1.add( layers.MaxPooling2D(2,2))\n",
        "        self.model1.add( layers.Conv2D(filters = 64,kernel_size =(3,3), activation='relu'))   #64\n",
        "        self.model1.add( layers.BatchNormalization())\n",
        "        self.model1.add( layers.MaxPooling2D(2,2))\n",
        "        self.model1.add( layers.Conv2D(filters = 32,  kernel_size =(5,5), activation= 'relu'))   #32\n",
        "        self.model1.add( layers.BatchNormalization())\n",
        "        self.model1.add( layers.MaxPooling2D(2,2))\n",
        "        self.model1.add( layers.Flatten())\n",
        "        self.model1.add( layers.Dense(units=512, activation= 'relu'))\n",
        "        self.model1.add( layers.Dropout(0.5))\n",
        "        self.model1.add(layers.Dense(units=10, activation='softmax'))\n",
        "        self.model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        print(\"모델1 구조 설정\")\n",
        "        return self.model1\n",
        "    def setmodel2(self):\n",
        "        self.model2 = models.Sequential()\n",
        "\n",
        "        self.model2.add(\n",
        "            layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(240, 240, 1),\n",
        "                          strides=(1, 1), padding='same'))  # 128\n",
        "        self.model2.add(layers.BatchNormalization())\n",
        "        self.model2.add(layers.MaxPooling2D(2, 2))\n",
        "        self.model2.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu')) # 64\n",
        "        self.model2.add(layers.BatchNormalization())\n",
        "        self.model2.add(layers.MaxPooling2D(2, 2))\n",
        "        self.model2.add(layers.Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))  # 32\n",
        "        self.model2.add(layers.BatchNormalization())\n",
        "        self.model2.add(layers.MaxPooling2D(2, 2))\n",
        "        self.model2.add(layers.Flatten())\n",
        "        self.model2.add(layers.Dense(units=512, activation='relu'))\n",
        "        self.model2.add(layers.Dropout(0.5))\n",
        "        self.model2.add(layers.Dense(units=10, activation='softmax'))\n",
        "        self.model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        print(\"모델2 구조 설정\")\n",
        "        return self.model2\n",
        "    def made_data(self, train_dir, val_dir, color):\n",
        "        train_datagen = ImageDataGenerator(\n",
        "            rescale = 1./255, zoom_range = 0.3,rotation_range=180)# 학습시마다 변경된 이미지\n",
        "        val_datagen = ImageDataGenerator(rotation_range=180, rescale = 1./255)\n",
        "        if color == \"rgb\":\n",
        "            train_generator = train_datagen.flow_from_directory(\n",
        "                train_dir,\n",
        "                target_size=(240, 240),\n",
        "                batch_size=16,\n",
        "                class_mode = 'categorical',\n",
        "                color_mode='rgb')\n",
        "            val_generator = val_datagen.flow_from_directory(\n",
        "                val_dir,\n",
        "                target_size=(240, 240),\n",
        "                batch_size=16,\n",
        "                class_mode = 'categorical',color_mode='rgb') #binary\n",
        "        elif color == \"gray\":\n",
        "            train_generator = train_datagen.flow_from_directory(\n",
        "                train_dir,\n",
        "                target_size=(240, 240),\n",
        "                batch_size=16,\n",
        "                class_mode='categorical',\n",
        "                color_mode='grayscale')\n",
        "            val_generator = val_datagen.flow_from_directory(\n",
        "                val_dir,\n",
        "                target_size=(240, 240),\n",
        "                batch_size=16,\n",
        "                class_mode='categorical', color_mode='grayscale')  # binary\n",
        "            # tf.data.Dataset으로 변환\n",
        "        self.train_dataset = tf.data.Dataset.from_generator(\n",
        "            lambda: train_generator,\n",
        "            output_signature=(\n",
        "                tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
        "                tf.TensorSpec(shape=(None, 6), dtype=tf.float32)))\n",
        "\n",
        "        self.val_dataset = tf.data.Dataset.from_generator(\n",
        "            lambda: val_generator,\n",
        "            output_signature=(\n",
        "                tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
        "                tf.TensorSpec(shape=(None, 6), dtype=tf.float32)))\n",
        "\n",
        "        # 무한 반복을 위한 repeat() 적용\n",
        "        train_dataset = train_dataset.repeat()  # 학습 데이터 무한 반복\n",
        "        val_dataset = val_dataset.repeat()      # 검증 데이터 무한 반복\n",
        "\n",
        "    def history(self):\n",
        "        plt.plot(self.history_model1.history['accuracy'])\n",
        "        plt.plot(self.history_model1.history['val_accuracy'])\n",
        "        plt.plot(self.history_model2.history['accuracy'])\n",
        "        plt.plot(self.history_model2.history['val_accuracy'])\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.xlabel('Accuracy')\n",
        "        plt.legend(['Train_model1', 'Test_model1','Train_model2', 'Test_model2'], loc='upper left')\n",
        "        plt.show()\n",
        "\n",
        "    def set_models(self):\n",
        "        self.models.append(self.model1)\n",
        "        self.models.append(self.model2)\n",
        "        print(\"모델 저장\")\n",
        "    def save_model(self, model,filepath):\n",
        "        model.save(filepath)\n",
        "        print(filepath + \"모델 저장\")\n",
        "    def made_voting_model(self, model1, model2):\n",
        "        self.model = [model1, model2]\n",
        "    def made_model(self,model):\n",
        "        if model == \"natural\":\n",
        "            # 앙상블 모델 함수 활성화 추가 코드\n",
        "            self.model1 = self.setmodel1()\n",
        "            self.made_data(self.train_dir, self.val_dir, self.color) #model1\n",
        "            self.history_model1 = self.model1.fit(self.train_generator, epochs=10, validation_data=self.val_generator,validation_steps=1)\n",
        "            return self.model1\n",
        "        elif model == \"canny\":\n",
        "            self.model2 = self.setmodel2()\n",
        "            self.made_data(self.train_dir1, self.val_dir1, self.gray) #model2\n",
        "            self.history_model2 = self.model2.fit(self.train_generator, epochs=10, validation_data=self.val_generator, validation_steps=1)\n",
        "            return self.model2\n",
        "        self.history()\n",
        "\n",
        "    def predict(self, model):\n",
        "        pred = model.predict()\n",
        "        return pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "U5M77FruAxrQ",
        "outputId": "d45cc44f-9cc9-4e55-f08e-6107733cf0b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델2 구조 설정\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'train/model2'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-d2f0ecc95933>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/GPU:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmade_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"canny\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"canny.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmade_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"natural\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-fb7c99a7a011>\u001b[0m in \u001b[0;36mmade_model\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"canny\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetmodel2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmade_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dir1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_dir1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#model2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory_model2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-fb7c99a7a011>\u001b[0m in \u001b[0;36mmade_data\u001b[0;34m(self, train_dir, val_dir, color)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 class_mode = 'categorical',color_mode='rgb') #binary\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gray\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             self.train_generator = train_datagen.flow_from_directory(\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m240\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m240\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0mkeep_aspect_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     ):\n\u001b[0;32m-> 1138\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1139\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train/model2'"
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "    with tf.device('/GPU:0'):\n",
        "        model = Model()\n",
        "        model2 = model.made_model(\"canny\")\n",
        "        model.save_model(model2, \"canny.h5\")\n",
        "        model1 = model.made_model(\"natural\")\n",
        "        model.save_model(model1, \"model.h5\")\n",
        "        voting_model1 = model.made_voting_model( model1, model2)\n",
        "    # 배깅\n",
        "    \"\"\"\n",
        "    model.train_dir = \"train1/model1\"\n",
        "    model.val_dir = \"val1/model1\"\n",
        "    model.train_dir1 = \"train1/model2\"\n",
        "    model.val_dir1 = \"val1/model2\"\n",
        "    model3 = model.made_model(\"canny\")\n",
        "    model4 = model.made_model(\"natural\")\n",
        "    voting_model2 = model.made_voting_model()\n",
        "    \"\"\"\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}