{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jX7ukQPOAxrM"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/rickiepark/handson-ml3/blob/main/12_custom_models_and_training_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFcMpxP2AxrN",
        "tags": []
      },
      "source": [
        "# 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xNKQVwanAxrN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "675bac04-8273-4c57-9b69-f889efa7a20e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=181xBl-rU9gBAL8-iEZbPNxKzPZY-QCGu\n",
            "From (redirected): https://drive.google.com/uc?id=181xBl-rU9gBAL8-iEZbPNxKzPZY-QCGu&confirm=t&uuid=b86dba6b-dd00-4ae0-b8c1-568901641bee\n",
            "To: /content/dataset.zip\n",
            "100%|██████████| 1.65G/1.65G [00:25<00:00, 64.3MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/dataset.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import gdown\n",
        "import numpy as np\n",
        "\n",
        "file_id = '181xBl-rU9gBAL8-iEZbPNxKzPZY-QCGu'\n",
        "download_url = f'https://drive.google.com/uc?id={file_id}'\n",
        "\n",
        "\n",
        "destination_path = '/content/dataset.zip'  # 파일 경로 설정\n",
        "\n",
        "# 다운로드 시작\n",
        "gdown.download(download_url, destination_path, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0Ddo9OPsAxrO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64eb7a45-d2d7-43af-aec3-26a747bd9b19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "압축이 /content/에 해제되었습니다.\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "\n",
        "zip_file_path = '/content/dataset.zip'\n",
        "extract_path = '/content/'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"압축이 {extract_path}에 해제되었습니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "JN8_1_vCAxrP"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "class Image_propressing:\n",
        "    def __init__(self):\n",
        "        #  폴더 경로\n",
        "        self.video_path = \"video/\"  # 비디오 폴더\n",
        "        self.nature_img_folder_path = \"nature/\"  # 전처리 이전 폴더\n",
        "        self.model1_img_folder_path = \"model1/\"  # 기본 모델 폴더\n",
        "        self.model2_img_folder_path = \"model2/\"  # 캐니 모델 폴더\n",
        "        self.train_path = \"train/\"\n",
        "        self.val_path = \"val/\"\n",
        "        self.data = []  # 전처리 전 데이터셋\n",
        "\n",
        "        self.label = [\"_ari\", \"_smallthe\", \"_corki\", \"_velkoz\", \"_thresh\", \"_gragas\", \"_atrox\", \"_kogmaw\", \"_8\", \"_9\"]  # 10개의 이미지 폴더에 대한 값\n",
        "        self.model_data1 = []  # 기본 이미지 모델 데이터셋\n",
        "        self.model_data2 = []  # 캐니 이미지 모델 데이터셋\n",
        "        self.valimgs = []    # 폴더 내 이미지 파일 이름을 저장할 리스트\n",
        "        self.trainimgs = []  # 폴더 내 이미지 파일 이름을 저장할 리스트\n",
        "        self.train_save = 3\n",
        "        self.val_save = 11\n",
        "    def reset_folder(self):\n",
        "        shutil.rmtree(self.train_path)\n",
        "        shutil.rmtree(self.val_path)\n",
        "        print(\"폴더 초기화\")\n",
        "    def set_folder(self):\n",
        "        os.makedirs(self.video_path, exist_ok=True)\n",
        "        os.makedirs(self.train_path + self.nature_img_folder_path, exist_ok=True)\n",
        "        os.makedirs(self.train_path + self.model1_img_folder_path, exist_ok=True)\n",
        "        os.makedirs(self.train_path + self.model2_img_folder_path, exist_ok=True)\n",
        "        os.makedirs(self.val_path + self.nature_img_folder_path, exist_ok=True)\n",
        "        os.makedirs(self.val_path + self.model1_img_folder_path, exist_ok=True)\n",
        "        os.makedirs(self.val_path + self.model2_img_folder_path, exist_ok=True)\n",
        "        for label in self.label:                   # 10개의 하위 폴더 생성 코드 추가 작성\n",
        "            os.makedirs(self.video_path + label, exist_ok=True)\n",
        "            os.makedirs(self.train_path + self.nature_img_folder_path + label, exist_ok=True)\n",
        "            os.makedirs(self.train_path + self.model1_img_folder_path + label, exist_ok=True)\n",
        "            os.makedirs(self.train_path + self.model2_img_folder_path + label, exist_ok=True)\n",
        "            os.makedirs(self.val_path + self.nature_img_folder_path + label, exist_ok=True)\n",
        "            os.makedirs(self.val_path + self.model1_img_folder_path + label, exist_ok=True)\n",
        "            os.makedirs(self.val_path + self.model2_img_folder_path + label, exist_ok=True)\n",
        "        print(\"setting folder\")\n",
        "\n",
        "    def save_train(self):\n",
        "        for label in self.label:\n",
        "            for file_name in os.listdir(self.video_path + label):\n",
        "                file_path = os.path.join(self.video_path + label, file_name)\n",
        "                video_capture = cv2.VideoCapture(file_path) # 동영상 로드\n",
        "                if not video_capture.isOpened():\n",
        "                    print(\"error_00: \" + label + \": 동영상 없음 \")\n",
        "                frame_count, train_count, val_count = 0, 0, 0\n",
        "                fps = video_capture.get(cv2.CAP_PROP_FPS)  # fps 설정\n",
        "                train_save = int(fps * self.train_save/10)  # 훈련에 사용될 이미지 정리  3초 간격으로 작성\n",
        "                val_save = int(fps * self.val_save/10)   # 훈련에 사용될 이미지 정리  11초 간격으로 작성\n",
        "                while True:\n",
        "                    ret, frame = video_capture.read()\n",
        "                    if not ret:\n",
        "                        break  # 프레임이 더 이상 없으면 반복문 종료\n",
        "                    # 프레임 파일 이름 형식 지정 및 저장\n",
        "                    if frame_count % train_save == 0:\n",
        "                        frame_filename = os.path.join(self.train_path + self.nature_img_folder_path + label, f\"{file_name}_{train_count:04d}.png\")\n",
        "                        frame = cv2.resize(frame, (240, 240))  # 이미지 크기 미리 정리\n",
        "                        cv2.imwrite(frame_filename, frame)\n",
        "                        train_count += 1\n",
        "                    elif frame_count % val_save == 0:  # elif 이미지 중복 제거\n",
        "                        frame_filename = os.path.join(self.val_path + self.nature_img_folder_path + label, f\"{file_name}_{val_count:04d}.png\")\n",
        "                        frame = cv2.resize(frame, (240, 240))  # 이미지 크기 미리 정리\n",
        "                        cv2.imwrite(frame_filename, frame)\n",
        "                        val_count += 1\n",
        "                    frame_count += 1\n",
        "                    # 자원 해제\n",
        "                video_capture.release()\n",
        "\n",
        "    # 이미지의 폴더 패스를 받고 이를 self.imgs 에 저장한다.\n",
        "    def set_img(self, model): #이미지 이름을 모두 따서 self.imgs에 저장해둠\n",
        "        self.valimgs = []\n",
        "        self.trainimgs = []\n",
        "        for label in self.label:\n",
        "            for img in os.listdir(self.val_path + model + label):\n",
        "                if os.path.splitext(img)[1].lower() in {\".png\", \".jpg\"}:\n",
        "                    self.valimgs.append([self.val_path, model, label, img])\n",
        "                else:\n",
        "                    print(\"error_01: 이미지 전처리 에러\")\n",
        "        for label in self.label:\n",
        "            for img in os.listdir(self.train_path + model + label):\n",
        "                if os.path.splitext(img)[1].lower() in {\".png\", \".jpg\"}:\n",
        "                    self.trainimgs.append([self.train_path, model, label, img])\n",
        "                else:\n",
        "                    print(\"error_01: 이미지 전처리 에러\")\n",
        "    \"\"\"\n",
        "    # 이미지 로테이트 함수\n",
        "    def made_model1_dataset(self):\n",
        "        self.set_img(self.nature_img_folder_path)\n",
        "        for path in self.valimgs:\n",
        "            image = cv2.imread(path[0]+path[1]+path[2]+\"/\"+path[3], cv2.IMREAD_COLOR)\n",
        "            height, width = image.shape[:2]\n",
        "            for i in range(12):\n",
        "                r_matrix = cv2.getRotationMatrix2D((width // 2, height // 2), i * 30, 1.0)\n",
        "                r_img = cv2.warpAffine(image, r_matrix, (width, height))\n",
        "                cv2.imwrite(self.val_path+self.model1_img_folder_path+path[2]+\"/\"+str(i)+path[3], r_img)\n",
        "        for path in self.trainimgs:\n",
        "            image = cv2.imread(path[0]+path[1]+path[2]+\"/\"+path[3], cv2.IMREAD_COLOR)\n",
        "            height, width = image.shape[:2]\n",
        "            for i in range(12):\n",
        "                r_matrix = cv2.getRotationMatrix2D((width // 2, height // 2), i * 30, 1.0)\n",
        "                r_img = cv2.warpAffine(image, r_matrix, (width, height))\n",
        "                cv2.imwrite(self.train_path+self.model1_img_folder_path+path[2]+\"/\"+str(i)+path[3], r_img)\n",
        "        # return self.model_data1    # data리스트 반환\n",
        "      \"\"\"\n",
        "    def made_model2_dataset(self):\n",
        "        self.set_img(self.nature_img_folder_path)\n",
        "        for path in self.valimgs:\n",
        "            image = cv2.imread(path[0] + path[1] + path[2]+\"/\"+path[3], cv2.IMREAD_GRAYSCALE)\n",
        "            img_c = cv2.Canny(image, 30, 80)\n",
        "            cv2.imwrite(path[0]+self.model2_img_folder_path+path[2]+\"/\"+path[3], img_c)\n",
        "        for path in self.trainimgs:\n",
        "            image = cv2.imread(path[0] + path[1] + path[2] + \"/\" + path[3], cv2.IMREAD_GRAYSCALE)\n",
        "            img_c = cv2.Canny(image, 30, 80)\n",
        "            cv2.imwrite(path[0] + self.model2_img_folder_path + path[2]+\"/\" + path[3], img_c)\n",
        "        print(\"생성 완료\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMGP = Image_propressing()\n",
        "IMGP.reset_folder()  # 폴더 초기화\n",
        "IMGP.set_folder()\n",
        "IMGP.save_train()\n",
        "#IMGP.made_model1_dataset()\n",
        "IMGP.made_model2_dataset()\n",
        "\"\"\"\n",
        "IMGP.train_path = \"train1/\"\n",
        "IMGP.val_path = \"val1/\"\n",
        "IMGP.train_save = 4\n",
        "IMGP.val_save = 13\n",
        "IMGP.set_folder()\n",
        "IMGP.save_train()\n",
        "IMGP.made_model1_dataset()\n",
        "IMGP.made_model2_dataset()\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "ZwvF52xsqCt9",
        "outputId": "6d345f7d-01dd-4347-ae44-c4185fdf026a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "폴더 초기화\n",
            "setting folder\n",
            "error_00: _ari: 동영상 없음 \n",
            "error_00: _smallthe: 동영상 없음 \n",
            "생성 완료\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nIMGP.train_path = \"train1/\"\\nIMGP.val_path = \"val1/\"\\nIMGP.train_save = 4\\nIMGP.val_save = 13\\nIMGP.set_folder()\\nIMGP.save_train()\\nIMGP.made_model1_dataset()\\nIMGP.made_model2_dataset()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1OI3MGjAxrQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import VotingClassifier,BaggingClassifier\n",
        "\n",
        "class Model:\n",
        "    def __init__(self):\n",
        "        self.models = []\n",
        "        self.model  = None\n",
        "        self.model1 = None\n",
        "        self.model2 = None\n",
        "        self.train_dir = \"train/nature\"\n",
        "        self.val_dir = \"val/nature\"\n",
        "        self.train_dir1 = \"train/model2\"\n",
        "        self.val_dir1 = \"val/model2\"\n",
        "        self.bagging_model1 = None\n",
        "        self.bagging_model2 = None\n",
        "        self.train_dataset = None\n",
        "        self.val_dataset = None\n",
        "        self.color =\"rgb\"\n",
        "        self.gray = \"gray\"\n",
        "        self.epoch = 10\n",
        "    def setmodel1(self):\n",
        "        self.model1 = models.Sequential()\n",
        "        self.model1.add( layers.Conv2D(filters = 32,kernel_size = (3,3), activation= 'relu', input_shape=(224, 224,3), strides = (1,1), padding = 'same')) #128\n",
        "        self.model1.add( layers.BatchNormalization())\n",
        "        self.model1.add( layers.MaxPooling2D(2,2))\n",
        "        self.model1.add( layers.Conv2D(filters = 64,kernel_size =(3,3), activation='relu'))   #64\n",
        "        self.model1.add( layers.BatchNormalization())\n",
        "        self.model1.add( layers.MaxPooling2D(2,2))\n",
        "        self.model1.add( layers.Conv2D(filters = 32,  kernel_size =(5,5), activation= 'relu'))   #32\n",
        "        self.model1.add( layers.BatchNormalization())\n",
        "        self.model1.add( layers.MaxPooling2D(2,2))\n",
        "        self.model1.add( layers.Flatten())\n",
        "        self.model1.add( layers.Dense(units=512, activation= 'relu'))\n",
        "        self.model1.add( layers.Dropout(0.5))\n",
        "        self.model1.add(layers.Dense(units=10, activation='softmax'))\n",
        "        self.model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        print(\"모델1 구조 설정\")\n",
        "        return self.model1\n",
        "\n",
        "    def setmodel2(self):\n",
        "        self.model2 = models.Sequential()\n",
        "\n",
        "        self.model2.add(\n",
        "            layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 1),\n",
        "                          strides=(1, 1), padding='same'))  # 128\n",
        "        self.model2.add(layers.BatchNormalization())\n",
        "        self.model2.add(layers.MaxPooling2D(2, 2))\n",
        "        self.model2.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu')) # 64\n",
        "        self.model2.add(layers.BatchNormalization())\n",
        "        self.model2.add(layers.MaxPooling2D(2, 2))\n",
        "        self.model2.add(layers.Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))  # 32\n",
        "        self.model2.add(layers.BatchNormalization())\n",
        "        self.model2.add(layers.MaxPooling2D(2, 2))\n",
        "        self.model2.add(layers.Flatten())\n",
        "        self.model2.add(layers.Dense(units=512, activation='relu'))\n",
        "        self.model2.add(layers.Dropout(0.5))\n",
        "        self.model2.add(layers.Dense(units=10, activation='softmax'))\n",
        "        self.model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        print(\"모델2 구조 설정\")\n",
        "        return self.model2\n",
        "    def made_data(self, train_dir, val_dir, color):\n",
        "        train_datagen = ImageDataGenerator(\n",
        "            rescale = 1./255, zoom_range = 0.3,rotation_range=180)# 학습시마다 변경된 이미지\n",
        "        val_datagen = ImageDataGenerator(rotation_range=180, rescale = 1./255)\n",
        "        if color == \"rgb\":\n",
        "            train_generator = train_datagen.flow_from_directory(\n",
        "                train_dir,\n",
        "                target_size=(224, 224),\n",
        "                batch_size=16,\n",
        "                class_mode = 'categorical',\n",
        "                color_mode='rgb')\n",
        "            val_generator = val_datagen.flow_from_directory(\n",
        "                val_dir,\n",
        "                target_size=(224, 224),\n",
        "                batch_size=16,\n",
        "                class_mode = 'categorical',color_mode='rgb') #binary\n",
        "            self.train_dataset = tf.data.Dataset.from_generator(\n",
        "            lambda: train_generator,\n",
        "            output_signature=(\n",
        "                tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
        "                tf.TensorSpec(shape=(None, 10), dtype=tf.float32)))\n",
        "\n",
        "            self.val_dataset = tf.data.Dataset.from_generator(\n",
        "                lambda: val_generator,\n",
        "                output_signature=(\n",
        "                    tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
        "                    tf.TensorSpec(shape=(None, 10), dtype=tf.float32)))\n",
        "        elif color == \"gray\":\n",
        "            train_generator = train_datagen.flow_from_directory(\n",
        "                train_dir,\n",
        "                target_size=(224, 224),\n",
        "                batch_size=16,\n",
        "                class_mode='categorical',\n",
        "                color_mode='grayscale')\n",
        "            val_generator = val_datagen.flow_from_directory(\n",
        "                val_dir,\n",
        "                target_size=(224, 224),\n",
        "                batch_size=16,\n",
        "                class_mode='categorical', color_mode='grayscale')  # binary\n",
        "\n",
        "            self.train_dataset1 = tf.data.Dataset.from_generator(\n",
        "            lambda: train_generator,\n",
        "            output_signature=(\n",
        "                tf.TensorSpec(shape=(None, 224, 224, 1), dtype=tf.float32),\n",
        "                tf.TensorSpec(shape=(None, 10), dtype=tf.float32)))\n",
        "\n",
        "            self.val_dataset1 = tf.data.Dataset.from_generator(\n",
        "                lambda: val_generator,\n",
        "                output_signature=(\n",
        "                    tf.TensorSpec(shape=(None, 224, 224, 1), dtype=tf.float32),\n",
        "                    tf.TensorSpec(shape=(None, 10), dtype=tf.float32)))\n",
        "            # tf.data.Dataset으로 변환\n",
        "        self.steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
        "        self.validation_steps = val_generator.samples // val_generator.batch_size\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def history(self):\n",
        "        plt.plot(self.history_model1.history['accuracy'])\n",
        "        plt.plot(self.history_model1.history['val_accuracy'])\n",
        "        plt.plot(self.history_model2.history['accuracy'])\n",
        "        plt.plot(self.history_model2.history['val_accuracy'])\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.xlabel('Accuracy')\n",
        "        plt.legend(['Train_model1', 'Test_model1','Train_model2', 'Test_model2'], loc='upper left')\n",
        "        plt.show()\n",
        "\n",
        "    def set_models(self):\n",
        "        self.models.append(self.model1)\n",
        "        self.models.append(self.model2)\n",
        "        print(\"모델 저장\")\n",
        "    def save_model(self, model,filepath):\n",
        "        model.save(filepath)\n",
        "        print(filepath + \"모델 저장\")\n",
        "    def made_voting_model(self, model1, model2):\n",
        "        self.model = [model1, model2]\n",
        "    def made_model(self,model):\n",
        "        if model == \"natural\":\n",
        "            # 앙상블 모델 함수 활성화 추가 코드\n",
        "            self.model1 = self.setmodel1()\n",
        "\n",
        "            self.made_data(self.train_dir, self.val_dir, self.color) #model1\n",
        "            self.history_model1 = self.model1.fit(self.train_dataset, epochs=self.epoch,steps_per_epoch= self.steps_per_epoch, validation_data= self.val_dataset,validation_steps=self.validation_steps)\n",
        "            self.history()\n",
        "            return self.model1\n",
        "        elif model == \"canny\":\n",
        "            self.model2 = self.setmodel2()\n",
        "            self.made_data(self.train_dir1, self.val_dir1, self.gray) #model2\n",
        "            self.history_model2 = self.model2.fit( self.train_dataset1, epochs=self.epoch,steps_per_epoch= self.steps_per_epoch, validation_data= self.val_dataset1, validation_steps=self.validation_steps)\n",
        "            self.history()\n",
        "            return self.model2\n",
        "\n",
        "    def predict(self, model):\n",
        "        pred = model.predict()\n",
        "        return pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U5M77FruAxrQ",
        "outputId": "65a41a79-4df9-4a0f-f225-9dfc9d9f8de2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델2 구조 설정\n",
            "Found 4872 images belonging to 10 classes.\n",
            "Found 852 images belonging to 10 classes.\n",
            "Epoch 1/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 104ms/step - accuracy: 0.2421 - loss: 7.9925 - val_accuracy: 0.2347 - val_loss: 149.8133\n",
            "Epoch 2/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 105ms/step - accuracy: 0.3148 - loss: 1.8045 - val_accuracy: 0.2428 - val_loss: 25.6169\n",
            "Epoch 3/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 105ms/step - accuracy: 0.3916 - loss: 1.5495 - val_accuracy: 0.2978 - val_loss: 6.8527\n",
            "Epoch 4/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 102ms/step - accuracy: 0.4336 - loss: 1.4480 - val_accuracy: 0.2476 - val_loss: 23.5492\n",
            "Epoch 5/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 104ms/step - accuracy: 0.4869 - loss: 1.2848 - val_accuracy: 0.3493 - val_loss: 5.4198\n",
            "Epoch 6/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 103ms/step - accuracy: 0.5196 - loss: 1.2246 - val_accuracy: 0.4605 - val_loss: 2.6325\n",
            "Epoch 7/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 100ms/step - accuracy: 0.5140 - loss: 1.2367 - val_accuracy: 0.5849 - val_loss: 1.3069\n",
            "Epoch 8/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - accuracy: 0.5414 - loss: 1.1215 - val_accuracy: 0.6029 - val_loss: 1.0180\n",
            "Epoch 9/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 101ms/step - accuracy: 0.5643 - loss: 1.0981 - val_accuracy: 0.2931 - val_loss: 2.1915\n",
            "Epoch 10/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 126ms/step - accuracy: 0.5694 - loss: 1.0559 - val_accuracy: 0.5969 - val_loss: 0.9850\n",
            "Epoch 11/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 122ms/step - accuracy: 0.5588 - loss: 1.1164 - val_accuracy: 0.5275 - val_loss: 1.8615\n",
            "Epoch 12/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 99ms/step - accuracy: 0.6086 - loss: 0.9965 - val_accuracy: 0.7117 - val_loss: 0.7951\n",
            "Epoch 13/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 127ms/step - accuracy: 0.6137 - loss: 0.9714 - val_accuracy: 0.7249 - val_loss: 0.7718\n",
            "Epoch 14/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - accuracy: 0.6079 - loss: 0.9781 - val_accuracy: 0.6220 - val_loss: 1.1586\n",
            "Epoch 15/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 100ms/step - accuracy: 0.6223 - loss: 0.9644 - val_accuracy: 0.6471 - val_loss: 0.8619\n",
            "Epoch 16/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 106ms/step - accuracy: 0.6330 - loss: 0.9155 - val_accuracy: 0.6041 - val_loss: 1.8095\n",
            "Epoch 17/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 105ms/step - accuracy: 0.6551 - loss: 0.8731 - val_accuracy: 0.4761 - val_loss: 2.3665\n",
            "Epoch 18/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 99ms/step - accuracy: 0.6581 - loss: 0.8853 - val_accuracy: 0.7608 - val_loss: 0.5758\n",
            "Epoch 19/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 100ms/step - accuracy: 0.6577 - loss: 0.8637 - val_accuracy: 0.5383 - val_loss: 1.1856\n",
            "Epoch 20/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 106ms/step - accuracy: 0.6731 - loss: 0.8316 - val_accuracy: 0.7189 - val_loss: 0.8322\n",
            "Epoch 21/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 100ms/step - accuracy: 0.6688 - loss: 0.8268 - val_accuracy: 0.7632 - val_loss: 0.7420\n",
            "Epoch 22/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 99ms/step - accuracy: 0.6717 - loss: 0.8038 - val_accuracy: 0.8086 - val_loss: 0.4975\n",
            "Epoch 23/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 97ms/step - accuracy: 0.6940 - loss: 0.7613 - val_accuracy: 0.7691 - val_loss: 0.6906\n",
            "Epoch 24/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 102ms/step - accuracy: 0.6837 - loss: 0.7587 - val_accuracy: 0.8086 - val_loss: 0.5340\n",
            "Epoch 25/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 100ms/step - accuracy: 0.6934 - loss: 0.7352 - val_accuracy: 0.7799 - val_loss: 0.5489\n",
            "Epoch 26/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - accuracy: 0.7155 - loss: 0.7345 - val_accuracy: 0.7967 - val_loss: 0.6908\n",
            "Epoch 27/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - accuracy: 0.7065 - loss: 0.7280 - val_accuracy: 0.7883 - val_loss: 0.4972\n",
            "Epoch 28/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 100ms/step - accuracy: 0.7088 - loss: 0.7037 - val_accuracy: 0.8110 - val_loss: 0.5118\n",
            "Epoch 29/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 104ms/step - accuracy: 0.7480 - loss: 0.6609 - val_accuracy: 0.5048 - val_loss: 9.0285\n",
            "Epoch 30/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 99ms/step - accuracy: 0.7046 - loss: 0.7547 - val_accuracy: 0.7823 - val_loss: 0.8982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "canny.h5모델 저장\n",
            "모델1 구조 설정\n",
            "Found 4872 images belonging to 10 classes.\n",
            "Found 852 images belonging to 10 classes.\n",
            "Epoch 1/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 277ms/step - accuracy: 0.3520 - loss: 6.7725 - val_accuracy: 0.0837 - val_loss: 8.2514\n",
            "Epoch 2/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 279ms/step - accuracy: 0.5485 - loss: 1.5087 - val_accuracy: 0.5084 - val_loss: 1.9534\n",
            "Epoch 3/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 276ms/step - accuracy: 0.6271 - loss: 1.0618 - val_accuracy: 0.7572 - val_loss: 0.8071\n",
            "Epoch 4/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 276ms/step - accuracy: 0.6944 - loss: 0.9178 - val_accuracy: 0.6615 - val_loss: 0.9992\n",
            "Epoch 5/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 272ms/step - accuracy: 0.7258 - loss: 0.8098 - val_accuracy: 0.8792 - val_loss: 0.3341\n",
            "Epoch 6/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 269ms/step - accuracy: 0.7648 - loss: 0.6834 - val_accuracy: 0.7488 - val_loss: 0.7354\n",
            "Epoch 7/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 271ms/step - accuracy: 0.7517 - loss: 0.7590 - val_accuracy: 0.8792 - val_loss: 0.3827\n",
            "Epoch 8/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 270ms/step - accuracy: 0.8194 - loss: 0.5701 - val_accuracy: 0.8684 - val_loss: 0.4116\n",
            "Epoch 9/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 271ms/step - accuracy: 0.8452 - loss: 0.4781 - val_accuracy: 0.9091 - val_loss: 0.2234\n",
            "Epoch 10/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 268ms/step - accuracy: 0.8483 - loss: 0.4803 - val_accuracy: 0.8971 - val_loss: 0.3240\n",
            "Epoch 11/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 269ms/step - accuracy: 0.8506 - loss: 0.4581 - val_accuracy: 0.9103 - val_loss: 0.2769\n",
            "Epoch 12/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 269ms/step - accuracy: 0.8634 - loss: 0.4121 - val_accuracy: 0.6926 - val_loss: 2.7496\n",
            "Epoch 13/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 270ms/step - accuracy: 0.8789 - loss: 0.3721 - val_accuracy: 0.9007 - val_loss: 0.4065\n",
            "Epoch 14/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 269ms/step - accuracy: 0.8805 - loss: 0.3852 - val_accuracy: 0.8457 - val_loss: 0.5218\n",
            "Epoch 15/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 269ms/step - accuracy: 0.8817 - loss: 0.3942 - val_accuracy: 0.9378 - val_loss: 0.1589\n",
            "Epoch 16/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 270ms/step - accuracy: 0.9123 - loss: 0.2489 - val_accuracy: 0.9330 - val_loss: 0.2153\n",
            "Epoch 17/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 270ms/step - accuracy: 0.8977 - loss: 0.3308 - val_accuracy: 0.8947 - val_loss: 0.4100\n",
            "Epoch 18/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 270ms/step - accuracy: 0.8954 - loss: 0.3830 - val_accuracy: 0.9306 - val_loss: 0.2788\n",
            "Epoch 19/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 270ms/step - accuracy: 0.9175 - loss: 0.2818 - val_accuracy: 0.7033 - val_loss: 1.4588\n",
            "Epoch 20/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 269ms/step - accuracy: 0.9165 - loss: 0.3120 - val_accuracy: 0.9486 - val_loss: 0.2307\n",
            "Epoch 21/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 267ms/step - accuracy: 0.9226 - loss: 0.3036 - val_accuracy: 0.9557 - val_loss: 0.1528\n",
            "Epoch 22/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 270ms/step - accuracy: 0.9258 - loss: 0.2298 - val_accuracy: 0.9306 - val_loss: 0.2299\n",
            "Epoch 23/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 272ms/step - accuracy: 0.9263 - loss: 0.2613 - val_accuracy: 0.9593 - val_loss: 0.1485\n",
            "Epoch 24/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 292ms/step - accuracy: 0.9280 - loss: 0.2350 - val_accuracy: 0.9294 - val_loss: 0.3048\n",
            "Epoch 25/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 286ms/step - accuracy: 0.9475 - loss: 0.1603 - val_accuracy: 0.9522 - val_loss: 0.1976\n",
            "Epoch 26/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 319ms/step - accuracy: 0.9474 - loss: 0.1901 - val_accuracy: 0.9569 - val_loss: 0.1580\n",
            "Epoch 27/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 328ms/step - accuracy: 0.9489 - loss: 0.1792 - val_accuracy: 0.8385 - val_loss: 0.9544\n",
            "Epoch 28/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 321ms/step - accuracy: 0.9295 - loss: 0.2866 - val_accuracy: 0.7739 - val_loss: 2.1162\n",
            "Epoch 29/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 306ms/step - accuracy: 0.9307 - loss: 0.2806 - val_accuracy: 0.8278 - val_loss: 0.8489\n",
            "Epoch 30/30\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 273ms/step - accuracy: 0.9482 - loss: 0.1889 - val_accuracy: 0.9414 - val_loss: 0.3850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model.h5모델 저장\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nmodel.train_dir = \"train1/model1\"\\nmodel.val_dir = \"val1/model1\"\\nmodel.train_dir1 = \"train1/model2\"\\nmodel.val_dir1 = \"val1/model2\"\\nmodel3 = model.made_model(\"canny\")\\nmodel4 = model.made_model(\"natural\")\\nvoting_model2 = model.made_voting_model()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "model = Model()\n",
        "model.epoch = 30\n",
        "model1 = model.made_model(\"natural\")\n",
        "model.save_model(model1, \"model.h5\")\n",
        "\n",
        "# 배깅\n",
        "\"\"\"\n",
        "model.train_dir = \"train1/model1\"\n",
        "model.val_dir = \"val1/model1\"\n",
        "model.train_dir1 = \"train1/model2\"\n",
        "model.val_dir1 = \"val1/model2\"\n",
        "model3 = model.made_model(\"canny\")\n",
        "model4 = model.made_model(\"natural\")\n",
        "voting_model2 = model.made_voting_model()\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "train_dir = \"train/nature\"\n",
        "val_dir = \"val/nature\"\n",
        "# 데이터 증강 (학습 데이터에만 적용)\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=180,       # 회전 범위 증가\n",
        ")\n",
        "\n",
        "# 검증 데이터는 증강하지 않음 (단순히 정규화만 적용)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# 학습 데이터 생성기\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,  # 학습 데이터 경로\n",
        "    target_size=(224, 224),  # VGG16의 입력 크기에 맞게 리사이즈\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',  # 다중 클래스 분류\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# 검증 데이터 생성기\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,  # 검증 데이터 경로\n",
        "    target_size=(224, 224),  # VGG16의 입력 크기에 맞게 리사이즈\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'  # 다중 클래스 분류\n",
        ")\n",
        "\n",
        "# tf.data.Dataset으로 변환\n",
        "train_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: train_generator,\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(None, 10), dtype=tf.float32)\n",
        "    )\n",
        ")\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: val_generator,\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(None, 10), dtype=tf.float32)\n",
        "    )\n",
        ")\n",
        "train_dataset = train_dataset.repeat()  # 학습 데이터 무한 반복\n",
        "val_dataset = val_dataset.repeat()      # 검증 데이터 무한 반복\n",
        "\n",
        "# VGG16 모델 불러오기 (pre-trained weights 사용, top layers 제외)\n",
        "vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# 모델에 Flatten 레이어 추가\n",
        "x = layers.Flatten()(vgg16_base.output)\n",
        "\n",
        "# Dense 레이어 추가 (출력 클래스 수에 맞게)\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "x = layers.Dropout(0.6)(x)  # Dropout 추가\n",
        "x = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "# 새로운 모델 정의\n",
        "vgg16 = models.Model(inputs=vgg16_base.input, outputs=x)\n",
        "\n",
        "# VGG16의 base 일부 레이어를 학습 가능하게 만들기\n",
        "for layer in vgg16_base.layers:\n",
        "    layer.trainable = False\n",
        "# 모델 컴파일\n",
        "vgg16.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 요약 정보 출력\n",
        "vgg16.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        },
        "id": "TDznmrcxaSe1",
        "outputId": "f291fa53-2ae4-441c-faf3-68e9a24f254e"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4872 images belonging to 10 classes.\n",
            "Found 852 images belonging to 10 classes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_199\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_199\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_19 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block1_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m1,792\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block1_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m36,928\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block1_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block2_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block2_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m147,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block2_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block3_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m295,168\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block3_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m590,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block3_conv3 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m590,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block3_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block4_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m1,180,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block4_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block4_conv3 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block4_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block5_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block5_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block5_conv3 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block5_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_19 (\u001b[38;5;33mFlatten\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │      \u001b[38;5;34m12,845,568\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m5,130\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block1_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block1_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block1_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block2_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block2_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block2_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block3_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block3_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block3_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block3_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block4_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block4_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block4_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block4_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block5_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block5_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block5_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block5_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">12,845,568</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m27,565,386\u001b[0m (105.15 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,565,386</span> (105.15 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,850,698\u001b[0m (49.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,850,698</span> (49.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# steps_per_epoch, validation_steps 설정\n",
        "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
        "validation_steps = val_generator.samples // val_generator.batch_size\n",
        "# 모델 학습\n",
        "history = vgg16.fit(\n",
        "    train_dataset,  # tf.data.Dataset 사용\n",
        "    steps_per_epoch=steps_per_epoch,  # 배치 크기에 맞춰 학습 스텝 설정\n",
        "    epochs=20,  # 에포크 수\n",
        "    validation_data=val_dataset,  # 검증 데이터\n",
        "    validation_steps=validation_steps  # 검증 배치 크기 맞추기\n",
        ")\n",
        "# 모델 저장\n",
        "model.save('vgg16.keras')"
      ],
      "metadata": {
        "id": "MSsRx7bPdn22",
        "outputId": "38ef29ca-38cb-4310-d456-80adec03c6cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 479ms/step - accuracy: 0.4105 - loss: 2.9120 - val_accuracy: 0.7308 - val_loss: 0.7872\n",
            "Epoch 2/20\n",
            "\u001b[1m 91/152\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 465ms/step - accuracy: 0.6244 - loss: 0.9082"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "named_estimators = [\n",
        "    (\"model1\", model1),\n",
        "    (\"vgg16\", vgg16),\n",
        "]\n",
        "voting_clf = VotingClassifier(named_estimators)\n"
      ],
      "metadata": {
        "id": "mF_iWbAEdQVl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}